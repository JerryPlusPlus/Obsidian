#### 架构
1. 编码器
2. 连接器
3. LLM
4. 生成器（可选项）

![[MLLM架构图.png]]

CLIP为代表的判别式，OFA为代表的生成式

**多模态上下文学习**技术为少样本学习方法，旨在使用少量的问答样例提示模型，提升模型的 few-shot 性能。提升性能的关键在于让模型有效地关注上下文，并将内在的问题模式泛化到新的问题上。以 Flamingo [10]为代表的工作通过在图文交错的数据上训练来提升模型关注上下文的能力。目前对于多模态上下文学习的研究还比较初步，有待进一步探索。

**多模态思维链**的基本思想是通过将复杂的问题分解为较简单的子问题，然后分别解决并汇总。相较于纯文本的推理，多模态的推理涉及更多的信息来源和更复杂的逻辑关系，因此要复杂得多。当前该方面的工作也比较少。

**LLM 辅助的视觉推理**方法探索如何利用 LLM 强大的内嵌知识与能力，并借助其他工具，设计各种视觉推理系统，解决各种现实问题。相比于通过端到端训练获得单一模型，这类方法一般关注如何通过免训练的方式扩展和加强 LLM 的能力，从而构建一个综合性的系统。

#### 1. 编码器


#### 2. 连接器


#### 3. LLM


#### 4. 生成器（可选项）

